{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-18 12:49:11.287806: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "No model was supplied, defaulted to t5-small and revision d769bba (https://huggingface.co/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "nlp = transformers.pipeline(\"summarization\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "nlp = transformers.pipeline(\"summarization\", model=\"facebook/bart-large-cnn\") \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#articles = pd.read_csv('../data/clean/\"QuantumComputing\"_2023-05-12 16:17:53.398356.csv')\n",
    "articles = pd.read_csv('../data/clean/\"quantumcomputing\"AND\"research\"_999.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 11:08:35\n",
      "2 11:09:46\n",
      "3 11:10:52\n",
      "4 11:12:26\n",
      "5 11:13:31\n",
      "6 11:15:22\n",
      "7 11:16:47\n",
      "8 11:18:21\n",
      "9 11:19:30\n"
     ]
    }
   ],
   "source": [
    "# SPEED: < 1.5 Minutes / Article\n",
    "\n",
    "summaries = []\n",
    "count = 0\n",
    "\n",
    "for i in range(10):  # len(articles)):\n",
    "    article = articles.at[i, 'body']\n",
    "\n",
    "    if type(article) != str:\n",
    "        continue\n",
    "\n",
    "    tokenized_input = tokenizer.tokenize(article)\n",
    "    \n",
    "    if len(tokenized_input) > 1023: # max input size for BART\n",
    "        article = ' '.join(tokenized_input[:1000]).replace(' ##', '')\n",
    "    \n",
    "    try:\n",
    "        summary = nlp(article) # set max size (! >30)\n",
    "\n",
    "    except:\n",
    "        summary = ''\n",
    "\n",
    "    if type(summary) == list:\n",
    "        summary = summary[0]['summary_text']\n",
    "    \n",
    "    if type(summary) == dict:\n",
    "        summary = summary['summary_text']\n",
    "    \n",
    "    articles.loc[i,'summary'] = summary\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    # if count % 5 == 0:\n",
    "    print(count, datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = []\n",
    "for i in range(10):\n",
    "    if type(articles.at[i, 'summary']) == dict:\n",
    "        summaries.append(articles.at[i, 'summary']['summary_text'])\n",
    "    if type(articles.at[i, 'summary']) == list:\n",
    "        summaries.append(articles.at[i, 'summary'][0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/misc/article_summary_list.txt', 'w') as file:\n",
    "    for item in summaries:\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

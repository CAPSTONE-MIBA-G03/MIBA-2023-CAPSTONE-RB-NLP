{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "csv_files = [f for f in os.listdir('../data/raw') if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['engine', 'se_link', 'se_title', 'se_description', 'se_source',\n",
       "       'n3k_link', 'n3k_title', 'n3k_body', 'n3k_author', 'n3k_published',\n",
       "       'bs_link', 'bs_title', 'bs_body'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty = pd.read_csv(f'../data/raw/{csv_files[0]}')\n",
    "df_dirty.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying all three links (se_link, n3k_link, bs_link) if they are not identical\n",
    "df_dirty.loc[(df_dirty['se_link'] != df_dirty['n3k_link']) | (df_dirty['se_link'] != df_dirty['bs_link'])]\n",
    "\n",
    "# Links are always identical here, so we can drop two of them and rename the remaining one\n",
    "df_dirty.drop(['n3k_link', 'bs_link'], axis=1, inplace=True)\n",
    "df_dirty.rename(columns={'se_link': 'link'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the three titles if they are not identical\n",
    "showme = df_dirty.loc[(df_dirty['se_title'] != df_dirty['n3k_title']) \n",
    "                      | (df_dirty['se_title'] != df_dirty['bs_title'])][['se_title', 'n3k_title', 'bs_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/tbxkzqv53pd3f16_r3jbmshw0000gn/T/ipykernel_5381/1064490035.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_dirty[col] = df_dirty[col].str.replace('\\n', ' ').str.replace('\\t', ' ').str.replace(' +', ' ').str.strip()\n"
     ]
    }
   ],
   "source": [
    "# Removing all '\\n' and '\\t' from n3k_title, n3k_body, bs_title, bs_body as well as leading and trailing whitespaces and more than\n",
    "# one whitespace in between words and replacing them with np.nan if they are empty strings\n",
    "for col in ['n3k_title', 'n3k_body', 'bs_title', 'bs_body']:\n",
    "    df_dirty[col] = df_dirty[col].str.replace('\\n', ' ').str.replace('\\t', ' ').str.replace(' +', ' ').str.strip()\n",
    "    df_dirty.loc[df_dirty[col] == '', col] = np.nan    \n",
    "\n",
    "# replacing n3k_titles with NA if they contain certain words and are less than 20 characters\n",
    "for word in ['robot', 'subscribe', 'register']:\n",
    "    df_dirty.loc[(df_dirty['n3k_title'].str.lower().str.contains(word))\n",
    "                 & (df_dirty['n3k_title'].str.len() < 20), 'n3k_title'] = np.nan\n",
    "    \n",
    "# doing the same with n3k_body\n",
    "for word in ['cookies', 'javascript', 'register', 'explorer', 'benzinga']:\n",
    "    df_dirty.loc[(df_dirty['n3k_body'].str.lower().str.contains(word))\n",
    "                 & (df_dirty['n3k_body'].str.len() < 400), 'n3k_body'] = np.nan\n",
    "\n",
    "# Doing the same for bs_title and bs_body\n",
    "for word in ['yahoo finance', 'bloomberg', 'yahoo news', 'navigation', 'the straits times']:\n",
    "    df_dirty.loc[(df_dirty['bs_title'].str.lower().str.contains(word))\n",
    "                 & (df_dirty['bs_title'].str.len() < 20), 'bs_title'] = np.nan\n",
    "\n",
    "for word in ['javascript', 'copyright', 'benzinga']:\n",
    "    df_dirty.loc[(df_dirty['bs_body'].str.lower().str.contains(word))\n",
    "                 & (df_dirty['bs_body'].str.len() < 400), 'bs_body'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding weather to keep bs_title or n3k_title and bs_body or n3k_body\n",
    "# Does it make sense to keep one part from one library and another part from another library knowing that its the same article?\n",
    "\n",
    "# Keeping both title and body of the library that has a longer body\n",
    "# E.g.: If for article 1, the n3k body is longer, we keep both  n3k_title and n3k_body\n",
    "\n",
    "for row in df_dirty:\n",
    "    if df_dirty['n3k_body'].str.len() > df_dirty['bs_body'].str.len():\n",
    "        df_dirty['title'] = df_dirty['n3k_title']\n",
    "        df_dirty['body'] = df_dirty['n3k_body']\n",
    "    else:\n",
    "        df_dirty['title'] = df_dirty['bs_title']\n",
    "        df_dirty['body'] = df_dirty['bs_body']\n",
    "\n",
    "df_dirty.drop(['n3k_title', 'n3k_body', 'bs_title', 'bs_body'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop that applies the above rules to each table in 'data/raw' and saves the cleaned table to \n",
    "# 'data/interim'\n",
    "for csv_file in csv_files:\n",
    "    df_dirty = pd.read_csv(f'../data/raw/{csv_file}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting news article info:   0%|          | 0/87 [00:00<?, ?it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info:  11%|█▏        | 10/87 [00:08<00:33,  2.32it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pipeline_executor import PipelineExecutor\n",
    "import nlp_analysis.word_wizard as ww\n",
    "\n",
    "topic = \"'quantumcomputing'AND'research'\"\n",
    "\n",
    "pipeline_executor = PipelineExecutor()\n",
    "quantum_df = pipeline_executor.execute(query=topic, max_articles=30, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating embeddings for column(s): ['body']: 100%|██████████| 1/1 [02:42<00:00, 162.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal K: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian/Documents/Learning/MiBA/classes/term3/Capstone/MIBA-2023-CAPSTONE-RB-NLP/nlp_analysis/word_wizard.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[new_column] = kmeans.labels_\n",
      "/Users/florian/Documents/Learning/MiBA/classes/term3/Capstone/MIBA-2023-CAPSTONE-RB-NLP/nlp_analysis/word_wizard.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[new_column + self.MEDOID_SUFFIX] = False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nlp_analysis.word_wizard.WordWizard at 0x161b7ed50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wizard = ww.WordWizard(df=quantum_df)\n",
    "wizard.create_word_embeddings(columns=['body'], lean=True) \\\n",
    "    .cluster_embeddings('body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_word_embeddings_clusters_medoids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_word_embeddings_clusters</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              body_word_embeddings_clusters_medoids\n",
       "body_word_embeddings_clusters                                      \n",
       "0.0                                                               3\n",
       "1.0                                                               3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking correctness of medoids (3 per cluster)\n",
    "wizard.df.groupby('body_word_embeddings_clusters').agg({'body_word_embeddings_clusters_medoids': \"sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensuring that medioids have different values\n",
    "len(wizard.df[wizard.df['body_word_embeddings_clusters_medoids'] == 1]['body_word_embeddings'].drop_duplicates()) == len(wizard.df[wizard.df['body_word_embeddings_clusters_medoids'] == 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "summarizer = transformers.pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1254\n",
      "cluster =  0.0 summary toolong\n",
      "1362\n",
      "cluster =  1.0 summary toolong\n",
      "417\n",
      "cluster =  0.0 summary [{'summary_text': 'Google is expanding its quantum computing research investments with Macquarie University and the University of Technology Sydney (UTS) The search giant is launching new partnership with University of Sydney and UNSW. Google’s Digital Future Initiative was announced in November last year, and earlier this month, Google appointed Grace Chung and Peter Bartlett to jointly lead the project.'}]\n",
      "1584\n",
      "cluster =  1.0 summary toolong\n",
      "634\n",
      "cluster =  1.0 summary [{'summary_text': 'IBM announced a new approach that it has developed in partnership with UC Berkley. The approach effectively counteracts the noise in IBM’s Eagle quantum computer. This is just one significant step toward quantum supremacy – a much-awaited threshold where the ability of quantum computers demonstrably exceeds that of conventional ones.'}]\n",
      "2587\n",
      "cluster =  0.0 summary toolong\n"
     ]
    }
   ],
   "source": [
    "sub_df = wizard.df[wizard.df['body_word_embeddings_clusters_medoids'] == 1]\n",
    "for i in range(len(sub_df)):\n",
    "    print(len(tokenizer.tokenize(sub_df.iloc[i]['body'])))\n",
    "    try:\n",
    "        summary = summarizer(sub_df.iloc[i]['body'])\n",
    "    except:\n",
    "        summary = 'toolong'\n",
    "    print('cluster = ', \n",
    "          sub_df.iloc[i]['body_word_embeddings_clusters'],\n",
    "          'summary', summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

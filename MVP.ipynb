{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "2023-06-16 09:39:25.129220: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from pipeline_executor import PipelineExecutor\n",
    "import nlp_analysis.word_wizard as ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting news article info:  14%|█▍        | 81/588 [01:00<03:59,  2.12it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info:  19%|█▊        | 109/588 [01:22<03:33,  2.25it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info:  29%|██▊       | 168/588 [02:08<05:37,  1.25it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info:  29%|██▉       | 170/588 [02:10<06:14,  1.12it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info:  34%|███▍      | 202/588 [02:45<04:38,  1.38it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info:  35%|███▌      | 206/588 [02:46<03:03,  2.08it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info:  78%|███████▊  | 460/588 [05:37<00:52,  2.43it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info:  82%|████████▏ | 482/588 [05:52<01:24,  1.25it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info:  82%|████████▏ | 484/588 [05:53<01:09,  1.49it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info:  93%|█████████▎| 546/588 [06:33<00:28,  1.47it/s]encoding error : input conversion failed due to input error, bytes 0x21 0x00 0x00 0x00\n",
      "Getting news article info: 100%|██████████| 588/588 [07:01<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "topic = \"roche\"\n",
    "\n",
    "pipeline_executor = PipelineExecutor()\n",
    "roche = pipeline_executor.execute(query=topic, max_articles=None, overwrite=True)\n",
    "\n",
    "# safe and load quantum_df using parquet\n",
    "roche.to_parquet('data/clean/roche.gzip', compression='gzip')\n",
    "roche = pd.read_parquet('data/clean/roche.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Creating word embeddings for paragraph: 100%|██████████| 20/20 [00:06<00:00,  3.24it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 16.23it/s]\n",
      "Extracting organizations for column paragraph: 100%|██████████| 4/4 [00:01<00:00,  3.99it/s]\n",
      "Creating summaries for medoids of column paragraph: 100%|██████████| 7/7 [03:50<00:00, 32.96s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nlp_analysis.word_wizard.WordWizard at 0x16eb85d10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roche = pd.read_parquet('data/clean/roche.gzip')\n",
    "roche = roche.sample(n=20)\n",
    "importlib.reload(ww)\n",
    "wizard = ww.WordWizard(df=roche, interest = 'paragraph')\n",
    "wizard.create_word_embeddings(wizard.interest, lean=True)\n",
    "wizard.create_sentence_embeddings(wizard.interest)\n",
    "wizard.cluster_embeddings(wizard.interest)\n",
    "wizard.entitiy_recognition(wizard.interest)\n",
    "wizard.summarize_medoids(wizard.interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18544431"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# silhouette score ain't working with too few samples I think\n",
    "from sklearn.cluster import KMeans\n",
    "df = wizard.df\n",
    "from sklearn.metrics import silhouette_score\n",
    "column = 'paragraph'\n",
    "k=2\n",
    "embed_column = column + wizard.EMB_SUFFIX\n",
    "kk = KMeans(n_clusters=k, n_init='auto').fit(df[embed_column].tolist())\n",
    "labels = kk.labels_\n",
    "silhouette_score(df[embed_column].tolist(), labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14\n",
       "0     8\n",
       "2     7\n",
       "Name: body_word_embeddings_clusters, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of entities in each cluster\n",
    "wizard.df['body_word_embeddings_clusters'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_word_embeddings</th>\n",
       "      <th>body_word_embeddings_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.06478899, -0.13545708, 0.06179996, 0.215222...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.109405935, -0.30240607, -0.03303288, 0.2109...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.09361677, -0.030796781, -0.11409727, 0.0525...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.15661505, -0.10956453, -0.25051394, 0.18294...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.13517544, 0.0073455237, -0.15610743, 0.0545...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.10058438, -0.09042827, -0.029156672, 0.0413...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 body_word_embeddings  \\\n",
       "0   [0.06478899, -0.13545708, 0.06179996, 0.215222...   \n",
       "11  [0.109405935, -0.30240607, -0.03303288, 0.2109...   \n",
       "13  [0.09361677, -0.030796781, -0.11409727, 0.0525...   \n",
       "19  [0.15661505, -0.10956453, -0.25051394, 0.18294...   \n",
       "21  [0.13517544, 0.0073455237, -0.15610743, 0.0545...   \n",
       "28  [0.10058438, -0.09042827, -0.029156672, 0.0413...   \n",
       "\n",
       "    body_word_embeddings_clusters  \n",
       "0                               1  \n",
       "11                              0  \n",
       "13                              2  \n",
       "19                              0  \n",
       "21                              2  \n",
       "28                              1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of medoids per cluster\n",
    "wizard.df[wizard.df['body_word_embeddings_clusters_medoids'] == True][['body_word_embeddings', 'body_word_embeddings_clusters']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
